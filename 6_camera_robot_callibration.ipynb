{"cells":[{"cell_type":"markdown","metadata":{"id":"i78dBPANiDq1"},"source":["# Camera robot kalibratie\n","\n","> Uit vorige opdrachten hebben we gezien hoe we pixelcoördinaten kunnen omzetten naar metrische coördinaten in cameraframe {C} via de intrinsieke matrix, en verder kunnen omzetten naar metrische coördinaten in een arbitrair frame {T}, bepaald door een dambordpatroon, via de extrinsieke matrix.\n","\n","> Dit is exact wat we nodig hebben voor onze robot manipulatie. Dit met het verschil dat we de punten niet nodig hebben in een arbitrair target frame {T} maar in het robot baselinkframe {B}. We hebben dus in totaal een matrix ${}^{B}T_{C}$ nodig die punten omzet van cameraframe {C} naar robot baseframe {B}. We kunnen hier gebruik maken van een handige techniek genaamd 'eye-to-hand' kalibratie. Dit wil zeggen dat we ons dambordpatroon zullen bevestigen aan de robot end-effector en hier beelden van zullen nemen met de camera. Op deze manier kunnen we terug door extrinsieke kalibratie de transformatiematrix ${}^{C}T_{T}$ van het cameraframe {C} naar het targetframe {T} bepalen, waarbij dit targetframe is bevestigd aan de robot end-effector. Als we matrix ${}^{B}T_{C}$ willen bekomen via matrix ${}^{C}T_{T}$, dan ontbreekt er nog de matrix ${}^{B}T_{T}$. Dit is de transformatie van de robot baselink naar het target frame. We krijgen dan:\n","\n","$${}^{B}T_{C}={}^{B}T_{T}*{}^{T}T_{C}={}^{B}T_{T}*({}^{C}T_{T})^{-1}$$\n","\n","> De totale transformatie van het robot baselinkframe naar het targetframe ${}^{B}T_{T}$ betsaat uit twee delen. Enerzijds bestaat dit uit de transformatie ${}^{B}T_{ee}$ van het robot baseframe naar het robot end-effector frame. Dit kennen we uit de voorwaartse kinematica van de robot die berekend wordt uit de joint waardes. Anderzijds bestaat deze uit de transformatie van de robot end-effector tot het dambordpatroon (frame {T}). Deze is gekend als we de exacte positie kennen van het dambordpatroon ten opzichte van de end-effector ${}^{T}T_{ee}$. Deze kennen we als we het dambordpatroon monteren in een gekende positie op de end-effector. Aangezien we beide kennen hebben we:\n","\n","$${}^{B}T_{T}={}^{B}T_{ee}*{}^{ee}T_{T}$$\n","\n","> Als we dus naast deze twee gekende matrices de extrinsieke kalibratiematrix kunnen bepalen, dan krijgen we de totale matrix ${}^{B}T_{C}$ die punten gedefiniëerd in het camera frame kan projecteren in het baselink frame. En eens de robot de positie van het object kent in baselink frame, dan kan deze daar naartoe bewegen. De totale matrix vermenigvuldiging is:\n","\n","$${}^{B}T_{C}={}^{B}T_{ee}*{}^{ee}T_{T}*{}^{T}T_{C}={}^{B}T_{ee}*{}^{ee}T_{T}*({}^{C}T_{T})^{-1}$$"]},{"cell_type":"markdown","metadata":{"id":"0VvSJ5crI-vR"},"source":["# 1. Importeer bibliotheken\n","\n","> Deze bibliotheken zijn nodig voor het volbrengen van dit script. In de CameraCalibration bibliotheek (die je vindt in de Classes folder op je Google Drive) vind je de code achter de commando's die je hier zal gebruiken. Deze cel zal een error geven als je niet met je Google Drive bent verbonden. Zorg er dus voor dat je links in de bestanden een folder 'drive' ziet staan naast de default 'sample_data'-folder. Indien niet, verbind met de drive door links op het mapje te klikken en vervolgens op het Google Drive symbool te klikken. Druk vervolgens nog eens op 'Runtime', 'Runtime opnieuw starten', om te refreshen.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1276,"status":"ok","timestamp":1699285703862,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"CFzfUcPdPcFH"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/My Drive/object_pose_estimation_online')\n","from Classes.CameraCalibration import *\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"markdown","metadata":{"id":"cp7ulL21JGVE"},"source":["# 2. Importeer alle beelden voor camera-robot kalibratie\n","\n","> Alle afbeeldingen bevinden zich onder de map /content/drive/My Drive/object_pose_estimation_online/data/camera_robot_calibration_images. Als je dit uitprint kan je zien dat dit een array is met alle 10 de padnamen naar elke afbeelding."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699285703862,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"OiGDKT5QJJYv","outputId":"af41d8e1-64aa-4928-85e2-a97119c55572"},"outputs":[],"source":["# Get all image's path names\n","robot_camera_calibration_images_file = '/content/drive/My Drive/object_pose_estimation_online/data/camera_robot_calibration_images/CRC_image_original_*.jpg'\n","images_path_names = get_image_path_names(robot_camera_calibration_images_file)\n","print(images_path_names)"]},{"cell_type":"markdown","metadata":{"id":"23Gb339_lFAE"},"source":["\n","\n","> We kunnen terug kijken hoe een dergelijke afbeelding eruit ziet. Merk op dat het dambordpatroon deze keer wordt vastgehouden door de robot.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"executionInfo":{"elapsed":830,"status":"ok","timestamp":1699285704690,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"zZmmscAIJJbE","outputId":"ab160f75-b6e1-449b-b4e9-2d781f82114f"},"outputs":[],"source":["# Preview image\n","image_path = images_path_names[0]\n","image = read_image(image_path)\n","cv2_imshow(image)"]},{"cell_type":"markdown","metadata":{"id":"xodZZRu2JVjX"},"source":["# 3. Laden van de baselink-target transformatie matrix\n","\n","> Voor een gegeven afbeelding van het dambordpatroon zullen we de transformatie matrix ${}^{C}T_{T}$ berekenen van camera frame naar target frame door middel van extrinsieke kalibratie. Om de gewenste baselink-camera transformatie ${}^{B}T_{C}$ te bekomen, hebben we nog de transformatiematrix nodig van baselink naar het target ${}^{B}T_{T}$, dit komt uit onze voorwaartse kinematica van de robot en hebben we reeds opgeslagen in /content/drive/My Drive/object_pose_estimation_online/data/camera_robot_calibration_images/baselink_target_transformations.npy. Je kan deze array printen en zien dat deze 10 keer een 4x4 transformatiematrix bevat (we hebben data van 10 afbeeldingen opgenomen). Per afbeelding hebben we dus de totale ${}^{B}T_{T}$ matrix opgeslagen.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":446,"status":"ok","timestamp":1699285705132,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"SIOvuBVtJkFn","outputId":"9def82eb-8f88-47b9-93ef-78a1fecf961a"},"outputs":[],"source":["# Get all corresponding baselink-target transformation matrices (numpy data)\n","baselink_target_transformations_file = '/content/drive/My Drive/object_pose_estimation_online/data/camera_robot_calibration_images/baselink_target_transformations.npy'\n","baselink_target_transformations = get_numpy_data(baselink_target_transformations_file)\n","print(np.shape(baselink_target_transformations))"]},{"cell_type":"markdown","metadata":{"id":"X9PL13skfVPt"},"source":["\n","\n","> We hebben hierboven de eerste afbeelding (index 0) ingeladen en hebben nu dus ook de eerste baselink-target transformatie nodig uit de array.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1699285705133,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"iuQqjVlqofV3","outputId":"b57068d9-bbf8-4825-c0ca-fabd98acccf2"},"outputs":[],"source":["# Get corresponding Baselink - Target transform for the 0th image\n","bt_transform = baselink_target_transformations[0]\n","print(\"Baselink-target transform: \\n\\n\" + str(bt_transform))"]},{"cell_type":"markdown","metadata":{"id":"p2sPv8aWfnn_"},"source":["> Deze matrix stelt dus de transformatiematrix voor van baselink frame {B} naar het dambordframe of targetframe {T}, ${}^{B}T_{T}$. Of in andere woorden, deze matrix kan punten beschreven in het target frame omzetten in het baselink frame.\n","\n","$$ {}^{B}P = {}^{B}T_{T}*{}^{T}P$$\n"]},{"cell_type":"markdown","metadata":{"id":"3LnDxH_MJpD3"},"source":["# 4. Laden van de berekende intrinsieke camera matrix\n","\n","> In vorige opgave heb je de intrinsieke matrix opgelsagen, deze werd automatisch opgeslagen onder /content/drive/My Drive/object_pose_estimation_online/data/matrix_files/intrinsic_camera_properties.npz. Deze kunnen we nu laden. De functie \"load_intrinsic_camera_matrix\" geeft je niet enkel de intrinsieke matrix, maar ook de distrotiecoëfficiënten nodig voor de kalibratie.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699285705133,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"xsein6ysJxkw"},"outputs":[],"source":["# Load intrinsic camera matrix and distortion coefficients\n","intrinsic_camera_matrix_file = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/intrinsic_camera_properties.npz'\n","mtx, dist = load_intrinsic_camera_matrix(intrinsic_camera_matrix_file)"]},{"cell_type":"markdown","metadata":{"id":"bj2yPUMAJ3_I"},"source":["# 5. Camera-robot kalibratie\n","\n","> In dit deel wordt de camera-robot kalibratie uitgevoerd. Dit door terug een extrinsieke kalibratie uit te voeren en deze matrix te inverteren en te vermenigvuldingen met de baselink-target matrix. Je bekomt dus de baselink-camera transformatiematrix ${}^{B}T_{C}$.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699285705133,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"jKbHvKm4QnZg","outputId":"8ea98d21-d81f-42b0-d33d-8da3aaa4641d"},"outputs":[],"source":["# Prepare object points in 3D space in meters\n","objp = get_object_points()\n","\n","# Read image\n","image = read_image(image_path)\n","\n","# Turn image to grayscale\n","gray = image_to_grayscale(image)\n","\n","# Find the corners in the chessbord calibration tool\n","corners = find_corners(gray)\n","\n","# Get extrinsic camera calibration matrix (camera-target transform)\n","ct_transform = extrinsic_calibration(objp, corners, mtx, dist)\n","print(\"Camera-target transform: \\n\\n\" + str(ct_transform))"]},{"cell_type":"markdown","metadata":{"id":"e1bCbpg6nxqZ"},"source":["\n","\n","> Nu dat je de transformatiematrix van het cameraframe naar het targetframe ${}^{C}T_{T}$ hebt, kan de deze gebruiken samen met de ${}^{B}T_{T}$ matrix om de totale ${}^{B}T_{C}$ matrix te bekomen. Let op dat je ${}^{C}T_{T}$ eerst nog moet inverteren! De baselink-camera matrix bereken je namelijk als volgt:\n","\n","$${}^{B}T_{C} = {}^{B}T_{T} * {}^{T}T_{C} $$\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699285705133,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"NTsOh9fFK0Au"},"outputs":[],"source":["# Invert the transform\n","tc_transform = invert_transform(ct_transform)\n","\n","# Compute Baselink - Camera transform using the \"multiply_transforms\" function\n","bc_transform = multiply_transforms(bt_transform, tc_transform)\n","\n","# Save the mean baselink - camera transformation matrix\n","baselink_camera_transformation_file = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/baselink_camera_transformation'\n","save_to_numpy(baselink_camera_transformation_file, bc_transform)\n","\n","print(\"Baselink-camera transform: \\n\\n\" + str(bc_transform))"]},{"cell_type":"markdown","metadata":{"id":"MAAzeDWIP_jd"},"source":["# 6. Test robot-camera calibration\n","\n","> In wat volgt kunnen we de robot-camera kalibratie testen. De inverse van de berekende ${}^{B}T_{C}$ kan namelijk punten gedefiniëerd in robot frame omzetten in camera frame. Samen met de intrinsieke matrix kunnen we dus punten omzetten van robot frame in pixel frame en dus virtueel geplaatste objecten in robot frame visualiseren in de afbeelding. We definiëren hier een kubus in coördinaten gedefiniëerd ten opzichte van het robot frame.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699285705608,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"nNXQppMZQYk1"},"outputs":[],"source":["# Define axis and box coordinates in world coordinate system\n","box = np.float32([[-0.1, -0.6, 0], [-0.1, -0.7, 0], [-0.2, -0.7, 0],\n","                  [-0.2, -0.6, 0], [-0.1, -0.6, -0.1], [-0.1, -0.7, -0.1], [-0.2, -0.7, -0.1],\n","                  [-0.2, -0.6, -0.1]]).reshape(-1, 3)"]},{"cell_type":"markdown","metadata":{"id":"4Y5vBBJhhiuQ"},"source":["\n","\n","> We willen nu punten gedefiniëerd in baselinkframe omzetten in camera frame. Dus hebben we de geïnverteerde nodig van ${}^{B}T_{C}$, namelijk ${}^{C}T_{B}$.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699285705608,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"P_TBPvpNQEGl"},"outputs":[],"source":["# Invert transform\n","cb_transform = invert_transform(bc_transform)"]},{"cell_type":"markdown","metadata":{"id":"80N1AahKh45X"},"source":["\n","> Uit de berekende baselink-camera matrix kunnen we afzonderlijk het rotatie gedeelte en het translatiegedeelte uithalen. Deze dienen we afzonderlijk aan het kalibratie algoritme te geven.\n","\n","$${}^{C}T_{B} = \\begin{bmatrix} r_{11} & r_{12} & r_{13} & t_{x} \\\\ r_{21} & r_{22} & r_{23} & t_{y} \\\\ r_{31} & r_{32} & r_{33} & t_{z}\\\\ 0 & 0 & 0 & 1 \\end{bmatrix} ; {}^{C}R_{B} = \\begin{bmatrix} r_{11} & r_{12} & r_{13}\\\\ r_{21} & r_{22} & r_{23}\\\\ r_{31} & r_{32} & r_{33}\\end{bmatrix} ; {}^{C}t_{B} = \\begin{bmatrix} t_{x} \\\\ t_{y} \\\\ t_{z}\\end{bmatrix}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699285705608,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"w_hOkVYyhy1j"},"outputs":[],"source":["# Retrieve rotation matrix and translation vector from cb_transform\n","cb_rot = cb_transform[:3, :3]\n","cb_trans = cb_transform[0:3, 3]"]},{"cell_type":"markdown","metadata":{"id":"ZbqOEQo9iFwd"},"source":["> Hier projecteren we de gedefiniëerde metrische coördinaten van de kubus (box) beschreven in het baselink frame in pixelcoördinaten en tekenen we deze op de afbeelding. Merk terug op dat aan de functie 'cv2.projectPoints' nu de translatie en rotatie matrices van het cameraframe naar het baselink frame worden meegegeven, dit was niet zo in het vorige script, daar waren dit de matrices van camera frame naar target frame."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699285705608,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"MtGzMOZkQEI6"},"outputs":[],"source":["# Project 3D box points to pixel coordinates\n","imgpts_box, _ = cv2.projectPoints(box, cb_rot, cb_trans, mtx, dist)\n","\n","# Draw box on image\n","image = draw_box1(image, imgpts_box.astype(int))"]},{"cell_type":"markdown","metadata":{"id":"Mzpu_8YCiNG8"},"source":["\n","\n","> Plot hieronder de afbeeldingen met de geprojecteerde pixels.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"executionInfo":{"elapsed":763,"status":"ok","timestamp":1699285706368,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"y_9XNcfMQELR","outputId":"a414d512-0740-49d5-a812-993b17e46d66"},"outputs":[],"source":["# Show result\n","cv2_imshow(image)"]},{"cell_type":"markdown","metadata":{"id":"EmbbJ9hhiil8"},"source":["\n","> Het resultaat laat inderdaad zien dat de gedefiniëerde kubus in baselink frame coördinaten mooi de juiste pixels triggert om het effect te creëren dat deze effectief in de ruimte aanwezig is. Je brein zal hoogst waarschijnlijk even de tijd nodig hebben om te zien dat de kubus wel degenlijk correct geplaatst is voor de robot. Je kan zelf wat spelen door de coördinaten van de kubus te veranderen.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"URorVLfZPxG0"},"source":["> Je kan ook zelf kijken welke pixels worden getriggerd door punten in metrische coördinaten, gedefiniëerd in het baselink frame te projecteren in pixel frame."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699285706369,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"EtMZE4zCP1Ax","outputId":"b812471b-4c98-4977-ad1d-b55c4306f296"},"outputs":[],"source":["# Define point\n","point = np.float32([0, 0, 0])\n","\n","# Project 3D point to pixel coordinates\n","imgpts_point, _ = cv2.projectPoints(point, cb_rot, cb_trans, mtx, dist)\n","print(imgpts_point)"]},{"cell_type":"markdown","metadata":{"id":"usBmvgyJx2Eu"},"source":["# 7. Omzetten van het coördinaat in camera frame naar het coördinaat in robot frame\n","\n","Door de uitgevoerde calibratie hebben we nu een matrix die metrische coördinaten in camera frame kan omzetten naar metrische coördinaten in robot frame. We kunnen dus nu het coördinaat van het object in camera frame uit vorig script omzetten naar coördinaten in robot frame. Dit doen we met de hierboven bepaalde baselink-camera transformatie."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699285706369,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"vsSVRWYCx2Eu","outputId":"e20c7a59-d9e2-43e3-aeab-0017188fb967"},"outputs":[],"source":["# Load camera coordinate\n","obj_camera_coor = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/obj_camera_coor.npy'\n","camera_coordinate = get_numpy_data(obj_camera_coor)\n","print(camera_coordinate)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699285706369,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"b6YCAcrUx2Eu","outputId":"d97f04db-0155-4a3a-8842-e1059a1f3a77"},"outputs":[],"source":["# Covert position to baselink frame\n","b_p = np.dot(bc_transform,  camera_coordinate)\n","print(\"Coördinaat in baselink frame: \\n\\n\" + str(np.reshape(b_p, (4, 1))))"]},{"cell_type":"markdown","metadata":{"id":"qZiRLNbcx2Ev"},"source":["Dit is dus het centerpunt van het object gedefiniëerd in het baselink frame van de robot. Om de robot naar een positie te kunnen sturen hebben we niet enkel een positie nodig maar hebben we een volledige transformatiematrix nodig van baselink naar target. Hieronder definiëren we nog welke oriëntatie we bij het object willen hebben door custom een 3x3 rotatiematrix te definiëren. Vervolgens brengen we die custom rotatiematrix en de berekende translatie matrix (positie) samen tot een volwaardige transformatiematrix."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699285706369,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"zhN5W4P0x2Ev","outputId":"2affaaa3-cea8-45e3-8ad8-f9bc23d93f38"},"outputs":[],"source":["# Create target orientation (custom)\n","R_target = np.array([[math.sqrt(2)/2, -math.sqrt(2)/2, 0],\n","       [-math.sqrt(2)/2, -math.sqrt(2)/2, 0],\n","       [0, 0, -1]])\n","print(\"Rotatie matrix: \\n\\n\" + str(R_target))\n","\n","# Create target position (calculated from image)\n","P_target = b_p\n","print(\"\\nTranslatie matrix: \\n\\n\" + str(np.reshape(P_target, (4, 1))))\n","\n","# Create total transformation (R and T)\n","bt_transform = np.zeros((4, 4))\n","bt_transform[:3, :3] = R_target\n","bt_transform[:, 3] = P_target\n","print(\"\\nTotale transformatiematrix: \\n\\n\" + str(bt_transform))"]},{"cell_type":"markdown","metadata":{"id":"vB3ZUhQvx2Ev"},"source":["Dit is wat we wilden bekomen. We kunnen nu als aller laatste stap deze matrix opslaan en deze in het volgende script visualiseren en de robot ernaar toe laten bewegen."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":325,"status":"ok","timestamp":1699285706691,"user":{"displayName":"Matthias De Ryck","userId":"08208255150401074413"},"user_tz":-60},"id":"WH5R0qBux2Ev"},"outputs":[],"source":["# Save the baselink - target transformation matrix\n","baselink_target_transformation_file = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/baselink_target_transformation'\n","save_to_numpy(baselink_target_transformation_file, bt_transform)"]},{"cell_type":"markdown","metadata":{"id":"0dt0Um5R4oxz"},"source":["# Vragen bij dit script:\n","\n","*  VRAAG 1: Wat is de x-, y-, en z- positie van de oorsprong van het targetframe {T} in het baselink frame {B} op het moment van het nemen van de eerste foto?\n","*  VRAAG 2: Wat is de x-, y-, en z- positie van de oorsprong van het targetframe {T} in het camera frame {C} op het moment van het nemen van de eerste foto?\n","*  VRAAG 3: Welk pixelcoördinaat wordt er getriggerd als een punt op coördinaat (0, -0.6, 0.0) meter in het baselink frame wordt geplaatst?"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
