{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7_send_robot_to_target.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1-2wTcGgyU_CXnBynVTvCN2S9TTeuiKth","authorship_tag":"ABX9TyNePeAm/jjX1aLTLITfJBA/"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ftez1-f5qpPY"},"source":["# Stuur robot naar het object\n","\n","> Uit vorige opdrachten hebben we de positie van een target, gezien vanuit de camera, kunnen definiëren in robot frame. We zijn dus de transformatie ${}^{B}T_{T}$ bekomen. Dit is de positie waar de robot naartoe moet bewegen. Uit de voorwaartse kinematica van een robot weten we dat als we de joint-coördinaten $q$ van een robot kennen, we de voorwaartste transformatie kunnen bepalen, m.a.w. de positie van de end-effector beschreven in het baselink frame. Deze positie wordt voorgesteld door de transformatiematrix van het baselinkframe {B} naar het end-effector frame {ee} zijnde ${}^{B}T_{ee}$. Het doel is dus om de joint-coördinaten zodanig te berekenen dat ${}^{B}T_{ee}$ gelijk wordt aan ${}^{B}T_{T}$. Dit zullen we doen gebruik makende van de inverse kinematica van de robot. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"FXsrNa5ISK-M"},"source":["# 1. Importeer bibliotheken\n","\n","> Deze bibliotheken zijn nodig voor het volbrengen van dit script. In de CameraCalibration bibliotheek (die je vindt in de Classes folder op je Google Drive) vind je de code achter de commando's die je hier zal gebruiken.  Deze bibliotheken zijn nodig voor het volbrengen van dit script. In de CameraCalibration bibliotheek (die je vindt in de Classes folder op je Google Drive) vind je de code achter de commando's die je hier zal gebruiken. Deze cel zal een error geven als je niet met je Google Drive bent verbonden. Zorg er dus voor dat je links in de bestanden een folder 'drive' ziet staan naast de default 'sample_data'-folder. Indien niet, verbind met de drive door links op het mapje te klikken en vervolgens op het Google Drive symbool te klikken. Druk vervolgens nog eens op 'Runtime', 'Runtime opnieuw starten', om te refreshen.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"2A9woDecyDAB"},"source":["import sys\n","sys.path.append('/content/drive/My Drive/object_pose_estimation_online')\n","from Classes.Visualization import *\n","from Classes.CameraCalibration import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P545-g8LZxTO"},"source":["# 2. Laden van de berekende baselink-target transformatiematrix \n","\n","> Dit is dus de eerder berekende transformatiematrix van baselink frame naar target frame. Met andere woorden, de positie van het target ten opzichte van de robot.\n","\n"]},{"cell_type":"code","metadata":{"id":"rC6wrHz5XdeY"},"source":["# Import baselink-target transformation matrix (numpy data)\n","baselink_target_transformation_file = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/baselink_target_transformation.npy'\n","bt_transform = get_numpy_data(baselink_target_transformation_file)\n","print(\"Baselink-target transform: \\n\\n\" + str(bt_transform))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J6GgYVU4mxMo"},"source":["# 3. Definiëren van de voorwaartse kinematica\n","\n","> De voorwaartse kinematica vertaalt de joint-coördinaten $q$ naar de positie van de end-effector in baselinkframe ${}^{B}T_{ee}$. Dit bestaat uit een aaneenschakeling van transformatiematrices die elk de verplaatsing voorstellen ten gevolge van één joint. De matrix ${}^{b}T_{1}$ stelt de transformatie voor van baselink naar joint 1 en wordt beïnvloed door de eerste joint-waarde $q[0]$. De matrix ${}^{1}T_{2}$ stelt de transformatie voor van joint 1 naar joint 2 en wordt beïnvloed door de tweede joint-waarde $q[1]$. En zo voort tot we aan de end-effector uitkomen. De functie \"robot_kinematics\" neemt joint variabelen (6 voor deze 6dof robot) en geeft de totale matrix ${}^{B}T_{ee}$ terug. \n","\n"]},{"cell_type":"code","metadata":{"id":"bOK2-jCWm0ob"},"source":["def robot_kinematics(q):\n","\n","    Tb1 = sp.Matrix([[-sp.cos(q[0]), 0, -sp.sin(q[0]), 0.050 * sp.cos(q[0])],\n","                     [-sp.sin(q[0]), 0, sp.cos(q[0]), 0.050 * sp.sin(q[0])],\n","                     [0, 1, 0, 0.457],\n","                     [0, 0, 0, 1]])\n","\n","    T12 = sp.Matrix([[-sp.sin(q[1]), -sp.cos(q[1]), 0, -0.440 * sp.sin(q[1])],\n","                     [sp.cos(q[1]), -sp.sin(q[1]), 0, 0.440 * sp.cos(q[1])],\n","                     [0, 0, 1, 0],\n","                     [0, 0, 0, 1]])\n","\n","    T23 = sp.Matrix([[-sp.cos(q[2]), 0, -sp.sin(q[2]), 0.035 * sp.cos(q[2])],\n","                     [-sp.sin(q[2]), 0, sp.cos(q[2]), 0.035 * sp.sin(q[2])],\n","                     [0, 1, 0, 0],\n","                     [0, 0, 0, 1]])\n","\n","    T34 = sp.Matrix([[-sp.cos(q[3]), 0, -sp.sin(q[3]), 0],\n","                     [-sp.sin(q[3]), 0, sp.cos(q[3]), 0],\n","                     [0, 1, 0, 0.420],\n","                     [0, 0, 0, 1]])\n","\n","    T45 = sp.Matrix([[-sp.cos(q[4]), 0, -sp.sin(q[4]), 0],\n","                     [-sp.sin(q[4]), 0, sp.cos(q[4]), 0],\n","                     [0, 1, 0, 0],\n","                     [0, 0, 0, 1]])\n","\n","    T5ee = sp.Matrix([[sp.cos(q[5]), -sp.sin(q[5]), 0, 0],\n","                     [sp.sin(q[5]), sp.cos(q[5]), 0, 0],\n","                     [0, 0, 1, 0],\n","                     [0, 0, 0, 1]])\n","\n","    bTee = Tb1 * T12 * T23 * T34 * T45 * T5ee\n","\n","    return np.array(bTee).astype(np.float64)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KDKBHSujqIjm"},"source":["\n","\n","> Hieronder wordt de voorwaartse kinematica geïmplementeerd. Je kan de waarden van de verschillende joints veranderen om te kijken wat dit van effect heeft op de transformatie matrix. Een numerieke matrix is echter niet echt visueel, in wat volgt kan je dit visueel voorstellen. \n","\n"]},{"cell_type":"code","metadata":{"id":"OKxm4ltNpQNM"},"source":["# Compute forward kinematics\n","joint_configuratie = [-pi/4, pi/10, 0, 0, 0, 0]  # In radialen\n","bee_transform = robot_kinematics(joint_configuratie)\n","print(\"Baselink-ee transform: \\n\\n\" + str(bee_transform))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"21L-y5dUZ6f-"},"source":["# 4. Berekenen van de gewenste joint variabelen met inverse kinematica\n","\n","> De inverse kinematica wordt berekend door middel van numerieke wiskunde. Een optimalisatieproces wordt uitgevoerd en probeert een kostfunctie te minimaliseren door enkel de joint variabelen te veranderen. De kost functie is hier de error tussen de positie waar de robot zich huidig bevindt ${}^{B}T_{ee}$ en de gewenste positie ${}^{B}T_{T}$. Je kan zien dat de doelfunctie \"distance_to_target\" een set joint variablelen inleest alsook de doelpositie. Eerst wordt de voorwaartse kinematica berekend. Vervolgens wordt de positie en orientatie error apart berekend en later samengevoegd. Door de norm te berekenen van de afwijking verkrijgen we telkens een positief scalair. De totale error geven we terug als kost. De 'scipy' minimizer zal verschillende $q$'s uitproberen en kijken dewelke de laagste kost heeft. Na x-aantal iteraties geeft hij de beste joint variablen terug. Dit zijn de joint-waarden die ervoor zorgen dat de robot op de target locatie zal belanden. \n","\n"]},{"cell_type":"code","metadata":{"id":"LWwPkGrlmCFh"},"source":["# Define objective function to minimize\n","def distance_to_target(q, T_target):\n","\n","    # Forward kinematics\n","    T = robot_kinematics(q)\n","\n","    # Position error\n","    target = T_target[:3, -1]\n","    squared_distance_to_target = np.linalg.norm(T[:3, -1] - target)\n","\n","    # Orientation error\n","    target_orientation = T_target[:3, :3]\n","    squared_distance_to_orientation = np.linalg.norm(T[:3, :3] - target_orientation)\n","\n","    # Total error\n","    squared_distance = squared_distance_to_target + squared_distance_to_orientation\n","\n","    return squared_distance"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uIsUNHlCq04X"},"source":["\n","\n","> Hieronder wordt de optimalisatie opgeroepen met de hierboven gedefiniëerde kostfunctie. Je kan zien dat de joint variabelen worden berekend voor de gegeven target positie. In de cel hieronder kan je de gewenste target transformatie bepalen waarvoor je de joint variabelen zal berekenen. In de 'T_target_custom' array kan je custom matrices opgeven. Let wel op, niet elke positie kan door de robot worden bereikt. Al je posities ingeeft die niet bereikbaar zijn, dan zal de inverse kinematica geen juiste oplossing terug geven. De default matrix zal al geen juist resultaat opleveren. Let ook op dat als je de waarden voor deze custom transformatie wilt bepalen, je de variabele die je aan het optimalisatiealgoritme geeft nog verandert van 'T_target', naar 'T_target_custom'.\n","\n"]},{"cell_type":"code","metadata":{"id":"vC6pnZ8CJfAS"},"source":["# Define target transform\n","T_target = bt_transform  # To reach the calculated target\n","T_target_custom = np.array([[1, 0, 0, 0],\n","                            [0, 1, 0, 0],\n","                            [0, 0, 1, 0],\n","                            [0, 0, 0, 1]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"etBLd5ZLmCIS"},"source":["# Execute minimization process\n","q_init = [0, 0, 0, 0, 0, 0]\n","joint_values = scipy.optimize.minimize(fun=distance_to_target, x0=q_init, args=T_target)['x']\n","print(joint_values)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JYwRzruIZ72P"},"source":["# 5. Visualiseer robot en frames\n","\n","> De volgende 'visualize'-functie print de baselink-end effector, baselink-camera, en baselink-target matrices uit die je in de vorige script hebt berekent en plot deze ook samen met de robot frames. Hier plot deze eerst de robot in zijn home positie. Je ziet de positie van de camera en je berekende object ten opzichte van de robot. Dit komt door de matrices die je hebt berekend. \n","\n"]},{"cell_type":"code","metadata":{"id":"l8-di2YK9siL"},"source":["# Visualize transform\n","pos = [0, 0, 0, 0, 0, 0]\n","visualize(pos)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XbupfUcb-CN_"},"source":["\n","> Nu zal de functie de robot plaatsen met de joint waardes die je hierboven hebt berekend op basis van de gewenste baselink-target transformatie. Je kan zien dat het end-effector frame van de robot wel degenlijk samenvalt met het target-frame. Merk op dat aan de 'visualize'-functie de berekende waarden van de joint variabelen worden meegegeven om de target positie te bekomen.\n","\n"]},{"cell_type":"code","metadata":{"id":"d9VqyiTf4K6h"},"source":["# Visualize transform\n","pos = joint_values\n","visualize(pos)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"No42vJ_X8Kpg"},"source":["\n","\n","> Je kan hier duidelijk zien dat als je de inverse kinematica berekent van de baselink-target transformatiematrix uit de afbeelding van het object, dat je joint waardes bekomt die de robot wel degenlijk naar het object sturen. De robot zou dit object nu kunnen grijpen en op een andere locatie zetten.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FulTeLf5G5-s"},"source":["*  VRAAG 1: Wat is de positie van de end-effector in cartesiaanse coördinaten als de robot in zijn home positie staat?\n","\n","$$q = ([0, 0, 0, 0, 0, 0])$$\n","\n","*  VRAAG 2: Wat zijn de nodige joint variabelen om de robot in volgende positie te krijgen:\n","\n","$${}^{B}T_{T} = \\begin{bmatrix} -\\sqrt(2)/2 & \\sqrt(2)/2 & 0 & 0.4 \\\\ \\sqrt(2)/2 & \\sqrt(2)/2 & 0 & -0.4 \\\\ 0 & 0 & -1 & 0.4\\\\ 0 & 0 & 0 & 1 \\end{bmatrix}$$ \n"]},{"cell_type":"markdown","metadata":{"id":"8ViRzK6f8hKQ"},"source":["\n","\n","> **Algemene conclusie:** Door het introduceren van een camera genereren we een closed-loop waardoor de robot meer info heeft over zijn omgeving, en dus objecten geplaatst in op voorhand ongedefiniëerde locaties toch kan grijpen. Dit zorgt voor veel flexibelere robotica oplossingen met gigantisch veel meer mogelijkheden dan de standaard positie gestuurde robots. Bij deze was dit het einde van dit deel van het labo. Hopelijk heb je wat bijgeleerd. In de vakken Machinevisie (3e BA) en Industriële Robotica (MA EM) gaan we veel dieper in op alles wat in dit labo werd gezien. \n","\n","> Voor verdere vragen of feedback over dit labo kan je mij steeds contacteren via matthias.deryck@kuleuven.be.\n","\n","\n","\n"]}]}