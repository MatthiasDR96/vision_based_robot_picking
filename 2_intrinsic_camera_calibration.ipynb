{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_intrinsic_camera_calibration.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rXxZHkk9Vif2"},"source":["# Intrinsieke camera kalibratie\n","\n","\n","> In dit script gaan we de camera kalibreren. Dit wil zeggen dat we opzoek zijn naar de intrinsieke camera matrix. Deze matrix zet metrische coördinaten (X, Y, Z) gedefiniëerd in het cameraframe {C} om in pixelcoördinaten (u, v). We kunnen dit schrijven in matrix notatie:\n","\n","$$\\begin{bmatrix} u'\\\\ v' \\\\ w' \\end{bmatrix} = \\begin{bmatrix} \\frac{f_{x}}{\\rho_{w}} & 0 & u_{0} \\\\ 0 & \\frac{f_{y}}{\\rho_{h}} & v_{0} \\\\ 0 & 0 & 1 \\end{bmatrix}*\\begin{bmatrix} X\\\\ Y \\\\ Z \\end{bmatrix}$$ \n","\n","> Waarbij w' een schaal factor is en de werkelijke pixelcoördinaten kunnen worden voorgesteld door: $u = \\frac{u'}{w'}$ en $v = \\frac{v'}{w'}$. Als we dit stelsel uitschrijven dan zien we inderdaad dat :\n","\n","$$u'=\\frac{f_{x}*X}{\\rho_{w}} + u_{0}*Z$$\n","\n","$$v'=\\frac{f_{y}*Y}{\\rho_{h}} + v_{0}*Z$$\n","\n","> En dus:\n","\n","$$u=\\frac{f_{x}*X}{\\rho_{w}*Z} + u_{0}$$\n","\n","$$v=\\frac{f_{y}*Y}{\\rho_{h}*Z} + v_{0}$$\n","\n","> We zien dus inderdaad dat als we het metrische coördinaat van een punt beschreven in cameraframe (X, Y, Z) kennen, dat we het overeenkomstige pixelcoördinaat (u,v) kunnen bepalen. Let erop dat we hier een dimensie verliezen door om te zetten van 3D naar 2D. We kunnen uit één beeld geen diepte bepalen. Om de ongekende parameters van de intrinsieke camera matrix te kunnen bepalen hebben we dus een set van punten nodig waarvan we de metrische coördinaten kennen alsook de overeenkomstige pixelcoördinaten. Als we zo genoeg bekenden kunnen genereren kunnen we deze gebruiken om uit het stelsel de onbekenden $(f_{x}, f_{y}, \\rho_{w}, \\rho_{h}, u_{0}, v_{0})$ op te lossen. Om dit te doen maken we gebruik van een dambordpatroon waar we de exacte afmetingen van kennen. "]},{"cell_type":"markdown","metadata":{"id":"n3oW8yjv_TXr"},"source":["# 1. Importeer biliotheken\n","\n","\n","> Deze bibliotheken zijn nodig voor het volbrengen van dit script. In de CameraCalibration bibliotheek (die je vindt in de Classes folder op je Google Drive) vind je de code achter de commando's die je hier zal gebruiken. Deze cel zal een error geven als je niet met je Google Drive bent verbonden. Zorg er dus voor dat je links in de bestanden een folder 'drive' ziet staan naast de default 'sample_data'-folder. Indien niet, verbind met de drive door links op het mapje te klikken en vervolgens op het Google Drive symbool te klikken. Druk vervolgens nog eens op 'Runtime', 'Runtime opnieuw starten', om te refreshen. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"AJ8Jeu0JEVMY"},"source":["import sys\n","sys.path.append('/content/drive/My Drive/object_pose_estimation_online')\n","from Classes.CameraCalibration import *\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qX_qEVFx_hfp"},"source":["# 2. Importeer alle beelden voor camera kalibratie\n","\n","> Voor de camera kalibratie hebben we beelden nodig van een kalibratietool, we gebruiken een dambordpatroon van 7x7 (hiermee wordt bedoeld dat er 7x7 zwart-zwart overgangen zijn, geen hokjes). Alle afbeeldingen bevinden zich onder de map /content/drive/My Drive/object_pose_estimation_online/data/camera_calibration_images. Met de asteriks hieronder in de padnaam wordt aangegeven dat uit deze map alle afbeelingen startende met \"CC_image_original_\" bedoeld worden. De methode \"get_image_path_names\" geeft alle aparte bestandsnamen terug en slaat deze op in \"images_path_names\". Als je dit uitprint kan je zien dat dit een array is met alle 10 de padnamen naar elke afbeelding. \n","\n"]},{"cell_type":"code","metadata":{"id":"AE3G70kQEVMg","scrolled":true},"source":["# Get all image's path names\n","camera_calibration_images_file = '/content/drive/My Drive/object_pose_estimation_online/data/camera_calibration_images/CC_image_original_*.jpg'\n","images_path_names = get_image_path_names(camera_calibration_images_file)\n","print(images_path_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VpGEXaH4TUBy"},"source":["\n","\n","> Als we een afbeelding willen weergeven kunnen we daar de onderstaande code voor gebruiken. Deze neemt de 1e afbeelding (Python indexeert vanaf 0 en doet dit met vierkante haakjes). We lezen het beeld uit met \"read_image\" en plotten deze met \"cv2_imshow()\". "]},{"cell_type":"code","metadata":{"id":"Rvg57CLI_FXc"},"source":["# Preview image\n","image_path = images_path_names[0]\n","image = read_image(image_path)\n","cv2_imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XslTMC19Vceb"},"source":["\n","\n","> Op deze afbeelding zien we dus ons dambordpatroon. Op dit dambordpatroon definiëren we een assenstelsel met x-, y-, en z-as. We definiëren voor elk van de hoekpunten (zwart-zwart overgangen) een metrisch coördinaat. De vakjes van het patroon zijn exact 0.02m breed. We kunnen nu bijvoorbeeld het hoekpunt rechts boven (omcirkeld) definiëren als de oorsprong met metrische coördinaten (X, Y, Z) = (0, 0, 0), het eerste coördinaat langs de x-as als (X, Y, Z) = (0.02, 0, 0), en het eerste coördinaat langs de y-as als (X, Y, Z) = (0, 0.02, 0). Zo kunnen we voor elk van de hoekpunten een metrisch coördinaat (X, Y, Z) definiëren. We kiezen hier z altijd 0. Als we nu met een algoritme in deze foto de hoeken detecteren in pixel coördinaten, dan kunnen we de gedefiniëerde metrische coördinaten (X, Y, Z) matchen met de gedetecteerde pixelcoördinaten (u, v) en deze 49 (7x7) gematchte paren gebruiken om de onbekenden uit de intrinsieke matrix te bepalen.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5XFajiqFABgg"},"source":["# 3. Testen van het corner detection algoritme\n","\n","\n","> Voor de camera kalibratie dienen we de exacte pixelcoördinaten te kennen van alle 49 hoekpunten in het patroon, er wordt eerst meegegeven dat we naar een 7x7 patroon zoeken. \n","\n"]},{"cell_type":"code","metadata":{"id":"LFhQFrmcA350"},"source":["# Define chessboard pattern to search for\n","pattern = (7, 7)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EaK1fVFuUctB"},"source":["\n","\n","> We zetten de afbeelding om naar grayscale, dit wordt gedaan om data te reduceren (van 3 RGB arrays naar 1 gray array). \n","\n"]},{"cell_type":"code","metadata":{"id":"nH0ndWKP_FZp"},"source":["# Convert RGB image to grayscale\n","gray = image_to_grayscale(image)\n","cv2_imshow(gray)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yG91FjqSUMOj"},"source":["\n","\n","> De functie \"find_corners\" geeft ons alle 49 pixel coördinaten (u, v) van elke zwart-zwart overgang in het patroon. Je kan deze uitprinten.\n","\n"]},{"cell_type":"code","metadata":{"id":"wpzKdVtfAYhk"},"source":["# Find the chess board corners in the image\n","corners = find_corners(gray)\n","print(corners)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Y0vh7Z5Uigx"},"source":["\n","\n","> De gedetecteerde hoeken kunnen worden gevisualiseerd op de afbeelding met de functie \"drawChessboardCorners\" van de cv2 bibliotheek. De kleuren geven aan in welke volgorde de hoeken zijn gedetecteerd en dus ook in welke volgorde deze worden opgeslagen in de array. Het eerste rode hoekpunt wordt als eerste opgeslagen en het laatse violette hoekpunt als laatste. \n","\n"]},{"cell_type":"code","metadata":{"id":"Hn3ucqOkAhEw"},"source":["# Show detected corners\n","image = cv2.drawChessboardCorners(image, pattern, corners, True)\n","cv2_imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7o9oZjMAIHs"},"source":["#4. Voorbereiding van de camera kalibratie met  10 afbeeldingen\n","\n","\n","> Bij camera kalibratie willen we alle 9 parameters van de intrinsieke camera matrix berekenen. Om voldoende data te hebben gebruiken we 10 afbeeldingen waarbij we telkens de pixelcoördinaten (u, v) van de hoekpunten bepalen en deze opslaan samen met de overeenkomstige metrische coördinaten (X, Y, Z). Deze metrische coördinaten definiëren we manueel. We zeggen bijvoorbeeld dat het eerste hoekpunt dat het algoritme detecteert (rood) overeenkomt met metrisch coördinaat (X, Y, Z) = (0, 0, 0). We definiëren het tweede rode hoekpunt dat het algoritme detecteert als liggende langs de x-as en geven dit dus het metrisch coördinaat (X, Y, Z) = (0.02, 0, 0). De functie \"get_object_points\" geeft ons al deze 49 manueel gedefiniëerde coördinaten, je kan deze uitprinten. \n","\n"]},{"cell_type":"code","metadata":{"id":"8w39UxFVEVMj"},"source":["# Get user defined world coordinates\n","objp = get_object_points()\n","print(objp)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TU8QJnKpcEmI"},"source":["\n","\n","> In een for-loop zullen alle hoekpunten (corners) van elke afbeelding worden gedetecteerd en gerelateerd aan de metrische coördinaten (objp). Per afbeelding worden deze telkens opgeslagen in 1 grote array dewelke we hier initialiseren alvoren de for-loop te starten. \n","\n"]},{"cell_type":"code","metadata":{"id":"23-3F4sxEVMb"},"source":["# Initialize empty arrays for world and pixel cooridnates\n","imgpoints = []\n","objpoints = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0tBQWohtcZft"},"source":["\n","\n","> In deze for-loop wordt het voorgaande gedaan voor 10 afbeeldingen van het dambordpatroon. Telkens wordt een afbeelding ingelezen, omgezet naar grayscale, hoekpunten gedetecteerd, en worden de corresponderende pixelcoördinaten en metrische coördinaten van elk hoekpunt toegevoegd aan de respectievelijke arras 'imgpoints' en 'objpoints'. Vervolledig de code door gebruik te maken van hetgeen je hiervoor hebt gezien. "]},{"cell_type":"code","metadata":{"id":"6vIjOk6mEVMl"},"source":["# Iterate over all images\n","for image_path in images_path_names:\n","\n","    # Read image from file\n","    image = \n","\n","    # Convert RGB image to grayscale\n","    gray = \n","\n","    # Find the chess board corners in the image\n","    corners = \n","\n","    # Add object points to objpoints list\n","    objpoints.append(objp)\n","\n","    # Add pixel coordinates to imgpoints list\n","    imgpoints.append(corners)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BdKo6zpqc-3f"},"source":["\n","\n","> Eens de for-loop voorbij is, zouden de arrays een correcte inhoud moeten hebben. Namelijk een array objpoints met 10 maal een 49x3 array, zijnde de metrische coordinaten (X, Y, Z) van de 49 hoekpunten in het patroon (moet (10, 49, 3) weergeven) en een array imgpoint met 10 maal een 49x2 array, zijnde de pixelcoordinaten (u, v) van de 49 hoekpunten in het patroon (moet (10, 49, 1, 2) weergeven). Let op: als je meerdere keren de for-loop uitvoert zonder de arrays 'objpoints' en 'imgpoints' terug te initialiseren, dan blijf je steeds nieuwe data toevoegen aan de arrays en gaan ook hun groottes verschillen van de (10, 49, 3), en (10, 49, 1, 2). Dit is op zich geen probleem, zo krijgt het algoritme voor intrinsieke kalibratie gewoon meer data. \n","\n"]},{"cell_type":"code","metadata":{"id":"nxc_Rq_qB_VO"},"source":["# Check dimensions of arrays\n","print(\"Dimensions of world coordinate array: \" + str(np.shape(objpoints)))\n","print(\"Dimensions of pixel coordinate array: \" + str(np.shape(imgpoints)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7f4i11VMDTeT"},"source":["# 5. Intrinsieke camera kalibratie\n","\n","> Eens we de twee arrays hebben met de pixelcoördinaten en de overeenkomstige metrische coördinaten, kunnen we deze twee aan een functie \"calibrate\\_camera\" geven die voor ons de intrinsieke matrix zal bepalen. Deze wordt automatisch met de tevens berekende distortie coëfficienten uitgeprint. In de matrix kan je herkennen wat de brandpuntafstand in x- en y-richting is alsook de camera centerpunten $u_{0}$ en $v_{0}$. \n","\n"]},{"cell_type":"code","metadata":{"id":"wWLWUoVUEVMn"},"source":["# Calibrate camera and obtain intrinsic camera matrix using the objpoints list and the imgpoints list\n","intrinsic_camera_matrix = calibrate_camera(objpoints, imgpoints)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ErrwDjiGedMm"},"source":["\n","\n","> Tot slot berekenen we nog de 'reprojection error'. Hierbij zal een algoritme de berekende pixelcoördinaten, gebruik makende van je berekende intrinsieke matrix, vergelijken met de pixelcoördinaten uit het corner detectie algoritme. Dit geeft een error die weergeeft hoe goed je kalibratie is (lager dan 0.1 is oké). \n","\n"]},{"cell_type":"code","metadata":{"id":"SvIr807VEVMq"},"source":["# Calculate reprojection error\n","reprojection_error = calculate_reprojection_error(intrinsic_camera_matrix, objpoints, imgpoints)\n","print(\"\\nTotal reprojection error: %f\" % (reprojection_error / float(len(objpoints))))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Txc0I2VaFvxL"},"source":["# 6. Test camera kalibratie\n","\n","\n","\n","> In wat volgt kunnen we de kalibratie testen. De intrinsieke matrix geeft ons namelijk weer welke pixel coördinaten overeenkomen met objecten gepositioneerd op een bepaalde locatie in het camera frame {C}. We kunnen dus coördinaten van een object die we virtueel plaatsen in het camera frame projecteren in pixel frame (dit is de basis van Augmented Reality). Hierbij laden we eerst terug onze berekende intrinsieke camera matrix.  \n","\n"]},{"cell_type":"code","metadata":{"id":"7xKjH8HXGq-R"},"source":["# Load intrinsic camera matrix and distortion coefficients\n","intrinsic_camera_matrix_file = \"/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/intrinsic_camera_properties.npz\"\n","mtx, dist = load_intrinsic_camera_matrix(intrinsic_camera_matrix_file)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZWSv-bIxfltO"},"source":["\n","\n","> We definiëren twee zaken:\n","\n","\n","*   De coordinaten van het camera assenstelsel. We definiëren de oorsprong op (X, Y, Z) = (0, 0, 0) in het camera frame, de x-as op (X, Y, Z) = (0.06, 0, 0) , de y-as op (X, Y, Z) = (0, 0.06, 0), en de z-as op (X, Y, Z) = (0, 0, 0.06). \n","*   De coördinaten van een virtueel vierkant van 0.04x0.04 meter in het camera frame. Eens op een afstand van 0.5 meter van de camera, 0.6 meter, en 1.7 meter.\n","\n","\n","> Voor deze beide zaken maken we gebruik van de intrinsieke matrix om te kijken met welke pixels deze overeenkomen. Als we deze pixels berekenen en projecteren op het beeld, dan krijgen we het effect alsof deze zaken zich werkelijk in de ruimte bevinden.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"yWm1VLsnFu9S"},"source":["# Define axis and box coordinates in camera coordinate system\n","axis = np.float32([[0.06, 0, 0], [0, 0.06, 0], [0, 0, 0.06], [0, 0, 0]])\n","square1 = np.float32([[0.08, 0.06, 0.5], [0.12, 0.06, 0.5], [0.12, 0.10, 0.5], [0.08, 0.10, 0.5]]).reshape(-1, 3)\n","square2 = np.float32([[0.08, 0.06, 0.6], [0.12, 0.06, 0.6], [0.12, 0.10, 0.6], [0.08, 0.10, 0.6]]).reshape(-1, 3)\n","square3 = np.float32([[0.08, 0.06, 1.7], [0.12, 0.06, 1.7], [0.12, 0.10, 1.7], [0.08, 0.10, 1.7]]).reshape(-1, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0wM5BQkmTjGR"},"source":["> Hier projecteren we de gedefiniëerde metrische coördinaten van het assenstelsel (axis) en de vierkanten (squareX) beschreven in het target frame, in pixelcoördinaten en tekenen we deze op de afbeelding. "]},{"cell_type":"code","metadata":{"id":"0y6J-RI3GNXT"},"source":["# Project 3D axis points to pixel coordinates\n","imgpts_axis, _ = cv2.projectPoints(axis, np.identity(3), np.zeros((3, 1)), mtx, dist)\n","\n","# Project 3D box points to pixel coordinates\n","imgpts_square1, _ = cv2.projectPoints(square1, np.identity(3), np.zeros((3, 1)), mtx, dist)\n","\n","# Project 3D box points to pixel coordinates\n","imgpts_square2, _ = cv2.projectPoints(square2, np.identity(3), np.zeros((3, 1)), mtx, dist)\n","\n","# Project 3D box points to pixel coordinates\n","imgpts_square3, _ = cv2.projectPoints(square3, np.identity(3), np.zeros((3, 1)), mtx, dist)\n","\n","# Draw axis on image\n","image = draw_axis(image, imgpts_axis)\n","\n","# Draw square 1 on image\n","image = draw_square(image, imgpts_square1)\n","\n","# Draw square 2 on image\n","image = draw_square(image, imgpts_square2)\n","\n","# Draw square 3 on image\n","image = draw_square(image, imgpts_square3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-yKCEL6PTV1V"},"source":["> Plot hier de afbeelding met de geprojecteerde pixels. "]},{"cell_type":"code","metadata":{"id":"gvqiAJvBGNZr"},"source":["# Show result\n","cv2_imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o3aLaDd-M5o4"},"source":["\n","\n","> Het resultaat laat inderdaad zien dat de gedefiniëerde objecten in camera frame coördinaten mooi de juiste pixels triggeren om het effect te creëren dat de objecten effectief in de ruimte aanwezig zijn. Merk op dat het geplotte frame het camera frame {C} voorstelt. De intrinsieke matrix projecteert dus metrische punten in dit coördinatenframe in pixelcoördinaten. De z-as is hier telkens weg van de camera gericht. De oorsprong bevindt zich in het camera centerpunt. Merk ook op dat hoe verder het vierkant van de camera staat (groter z-coördinaat), hoe kleiner dit vierkant wordt en hoe meer dit naar het centrum beweegt, ookal blijven de x- en y- coördinaten in camera frame gelijk. Motiveer dit aan de hand van de vergelijkingen voor het berekenen van de u- en v coördinaat. Je kan zelf wat spelen door de coördinaten van het vierkant te veranderen. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"jWp0d9WEM-gq"},"source":["\n","\n","> Je kan ook zelf kijken welke pixels worden getriggerd door punten in metrische coördinaten, gedefiniëerd in het cameraframe te projecteren in pixel frame.\n","\n"]},{"cell_type":"code","metadata":{"id":"6Fj1qW2INLp_"},"source":["# Define point\n","point = np.float32([0, 0, 0])\n","\n","# Project 3D point to pixel coordinates\n","imgpts_point, _ = cv2.projectPoints(point, np.identity(3), np.zeros((3, 1)), mtx, dist)\n","print(imgpts_point)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RD86AoPuGNp8"},"source":["\n","*   *VRAAG 1: Wat is het pixelcoördinaat dat overeenkomt met het 3e gedetecteerde hoekpunt in het dambordpatroon?*\n","*   *VRAAG 2: Hoeveel bedraagt de brandpuntafstand in pixelcoördinaten alsook het camera centerpunt in de x-richting van de gebruikte camera?*\n","*   *VRAAG 3: Welk pixelcoördinaat wordt er getriggerd als een punt op coördinaat (0.2, 0.2, 0.5) meter in het camera frame wordt geplaatst?*\n","\n","\n","\n","\n"]}]}