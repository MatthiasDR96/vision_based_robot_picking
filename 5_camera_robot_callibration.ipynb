{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_camera_robot_callibration.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1-HNl8DtgZE4ET1FPqZeORGnNafn_eV72","authorship_tag":"ABX9TyMMc7KSgPwj8T9I0mfs1PS7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"i78dBPANiDq1"},"source":["# Camera robot kalibratie\n","\n","> Uit vorige opdrachten hebben we gezien hoe we metrische coördinaten uit een arbitrair frame kunnen projecteren in pixelcoördinaten door gebruik te maken van de intrinsieke en extrinsieke camera matrix. Omgekeerd kunnen we dus ook objecten gezien vanuit de camera projecteren in een ander frame door de bekomen matrix ${}^{C}T_{T}$ te inverteren tot matrix ${}^{T}T_{C}$. Deze zet dus punten in camera frame of in target frame. \n","\n","$$ {}^{T}P = {}^{T}T_{C}*{}^{C}P$$\n","\n","> Dit is exact wat we nodig hebben voor onze robot manipulatie. Dit met het verschil dat we de punten niet nodig hebben in een arbitrair target frame {T} maar in het robot baselinkframe {B}. We kunnen hier gebruik maken van een handige techniek genaamd 'eye-to-hand' kalibratie. Dit wil simpelweg zeggen dat we ons dambordpatroon zullen bevestigen aan de robot end-effector en hier beelden van zullen nemen met de camera. De totale transformatie van het robot baselinkframe naar het targetframe ${}^{B}T_{T}$ is namelijk gekend als we de exacte positie kennen van het dambordpatroon (target frame) ten opzichte van de end-effector ${}^{T}T_{ee}$. Deze kennen we als we het dambordpatroon monteren in een gekende positie op de end-effector. En de transformatie van de baselink naar de end-effector ${}^{B}T_{ee}$ kennen we uit de robot kinematica als we de joint variabelen kennen. Dus hebben we: \n","\n","$${}^{B}T_{T}={}^{B}T_{ee}*{}^{ee}T_{T}$$ \n","> met \n","$${}^{ee}T_{T} = ({}^{T}T_{ee})^{-1} $$\n","\n","\n","> Als we deze gekende matrix vermenigvuldigen met de extrinsieke matrix die we kunnen berekenen:\n","\n","$${}^{B}T_{C}={}^{B}T_{T}*{}^{T}T_{C}={}^{B}T_{T}*({}^{C}T_{T})^{-1}$$\n","\n","> dan verkrijgen we de gewenste baselink-camera transformatie die punten gedefiniëerd in het camera frame kan projecteren in het baselink frame. En eens de robot de positie van het object kent in baselink frame, dan kan deze daar naartoe bewegen.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0VvSJ5crI-vR"},"source":["# 1. Importeer bibliotheken\n","\n","> Deze bibliotheken zijn nodig voor het volbrengen van dit script. In de CameraCalibration bibliotheek (die je vindt in de Classes folder op je Google Drive) vind je de code achter de commando's die je hier zal gebruiken. Deze cel zal een error geven als je niet met je Google Drive bent verbonden. Zorg er dus voor dat je links in de bestanden een folder 'drive' ziet staan naast de default 'sample_data'-folder. Indien niet, verbind met de drive door links op het mapje te klikken en vervolgens op het Google Drive symbool te klikken. Druk vervolgens nog eens op 'Runtime', 'Runtime opnieuw starten', om te refreshen. \n","\n"]},{"cell_type":"code","metadata":{"id":"CFzfUcPdPcFH"},"source":["import sys\n","sys.path.append('/content/drive/My Drive/object_pose_estimation_online')\n","from Classes.CameraCalibration import *\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cp7ulL21JGVE"},"source":["# 2. Importeer alle beelden voor camera-robot kalibratie\n","\n","> Alle afbeeldingen bevinden zich onder de map /content/drive/My Drive/object_pose_estimation_online/data/camera_robot_calibration_images. Als je dit uitprint kan je zien dat dit een array is met alle 10 de padnamen naar elke afbeelding. "]},{"cell_type":"code","metadata":{"id":"OiGDKT5QJJYv"},"source":["# Get all image's path names\n","robot_camera_calibration_images_file = '/content/drive/My Drive/object_pose_estimation_online/data/camera_robot_calibration_images/CRC_image_original_*.jpg'\n","images_path_names = get_image_path_names(robot_camera_calibration_images_file)\n","print(images_path_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23Gb339_lFAE"},"source":["\n","\n","> We kunnen terug kijken hoe een dergelijke afbeelding eruit ziet. Merk op dat het dambordpatroon deze keer wordt vastgehouden door de robot.\n","\n"]},{"cell_type":"code","metadata":{"id":"zZmmscAIJJbE"},"source":["# Preview image\n","image_path = images_path_names[0]\n","image = read_image(image_path)\n","cv2_imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xodZZRu2JVjX"},"source":["# 3. Laden van de baselink-target transformatie matrix\n","\n","> Voor een gegeven afbeelding van het dambordpatroon zullen we de transformatie matrix ${}^{C}T_{T}$ berekenen van camera frame naar target frame door middel van extrinsieke kalibratie. Om de gewenste baselink-camera transformatie ${}^{B}T_{C}$ te bekomen, hebben we nog de transformatiematrix nodig van baselink naar het target ${}^{B}T_{T}$, dit komt uit onze voorwaartse kinematica van de robot en hebben we reeds opgeslagen in /content/drive/My Drive/object_pose_estimation_online/data/camera_robot_calibration_images/baselink_target_transformations.npy. Je kan deze array printen en zien dat deze 10 keer een 4x4 transformatiematrix bevat (we hebben data van 10 afbeeldingen opgenomen). Per afbeelding hebben we dus de totale ${}^{B}T_{T}$ matrix opgeslagen. \n","\n"]},{"cell_type":"code","metadata":{"id":"SIOvuBVtJkFn"},"source":["# Get all corresponding baselink-target transformation matrices (numpy data)\n","baselink_target_transformations_file = '/content/drive/My Drive/object_pose_estimation_online/data/camera_robot_calibration_images/baselink_target_transformations.npy'\n","baselink_target_transformations = get_numpy_data(baselink_target_transformations_file)\n","print(np.shape(baselink_target_transformations))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X9PL13skfVPt"},"source":["\n","\n","> We hebben hierboven de eerste afbeelding (index 0) ingeladen en hebben nu dus ook de eerste baselink-target transformatie nodig uit de array.\n","\n"]},{"cell_type":"code","metadata":{"id":"iuQqjVlqofV3"},"source":["# Get corresponding Baselink - Target transform for the 0th image\n","bt_transform = baselink_target_transformations[0]\n","print(\"Baselink-target transform: \\n\\n\" + str(bt_transform))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p2sPv8aWfnn_"},"source":["> Deze matrix stelt dus de transformatiematrix voor van baselink frame {B} naar het dambordframe of targetframe {T}, ${}^{B}T_{T}$. Of in andere woorden, deze matrix kan punten beschreven in het target frame omzetten in het baselink frame. \n","\n","$$ {}^{B}P = {}^{B}T_{T}*{}^{T}P$$\n"," "]},{"cell_type":"markdown","metadata":{"id":"3LnDxH_MJpD3"},"source":["# 4. Laden van de berekende intrinsieke camera matrix\n","\n","> In vorige opgave heb je de intrinsieke matrix opgelsagen, deze werd automatisch opgeslagen onder /content/drive/My Drive/object_pose_estimation_online/data/matrix_files/intrinsic_camera_properties.npz. Deze kunnen we nu laden. De functie \"load_intrinsic_camera_matrix\" geeft je niet enkel de intrinsieke matrix, maar ook de distrotiecoëfficiënten nodig voor de kalibratie.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"xsein6ysJxkw"},"source":["# Load intrinsic camera matrix and distortion coefficients\n","intrinsic_camera_matrix_file = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/intrinsic_camera_properties.npz'\n","mtx, dist = load_intrinsic_camera_matrix(intrinsic_camera_matrix_file)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bj2yPUMAJ3_I"},"source":["# 5. Camera-robot kalibratie\n","\n","> In dit deel wordt de camera-robot kalibratie uitgevoerd. Dit door terug een extrinsieke kalibratie uit te voeren en deze matrix te inverteren en te vermenigvuldingen met de baselink-target matrix. Je bekomt dus de baselink-camera transformatiematrix ${}^{B}T_{C}$. Vervolledig onderstaande code door gebruik te maken van hetgeen hiervoor werd gezien alsook van de CameraCalibration bibliotheek onder '/content/drive/My Drive/object_pose_estimation_online/Classes' voor de fucnties om te inverteren en om matrices te vermenigvuldigen. \n"]},{"cell_type":"code","metadata":{"id":"jKbHvKm4QnZg"},"source":["# Prepare object points in 3D space in meters\n","objp = "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHRyiMCOKmX_"},"source":["# Read image\n","image = "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kiUgzOBPKmag"},"source":["# Turn image to grayscale\n","gray = "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CCgQ77aNKmc9"},"source":["# Find the corners in the chessbord calibration tool\n","corners = "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5PALSTqKmfi"},"source":["# Get extrinsic camera calibration matrix (camera-target transform)\n","ct_transform = \n","print(\"Camera-target transform: \\n\\n\" + str(ct_transform))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e1bCbpg6nxqZ"},"source":["\n","\n","> Nu dat je de transformatiematrix van het cameraframe naar het targetframe ${}^{C}T_{T}$ hebt, kan de deze gebruiken samen met de ${}^{B}T_{T}$ matrix om de totale ${}^{B}T_{C}$ matrix te bekomen. Let op dat je ${}^{C}T_{T}$ eerst nog moet inverteren! De baselink-camera matrix bereken je namelijk als volgt:\n","\n","$${}^{B}T_{C} = {}^{B}T_{T} * {}^{T}T_{C} $$\n","\n"]},{"cell_type":"code","metadata":{"id":"NTsOh9fFK0Au"},"source":["# Invert the transform\n","tc_transform = "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3otRLDTOK0Fu"},"source":["# Compute Baselink - Camera transform using the \"multiply_transforms\" function\n","bc_transform = "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2mhqlzpQw0k"},"source":["# Save the mean baselink - camera transformation matrix\n","baselink_camera_transformation_file = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/baselink_camera_transformation'\n","save_to_numpy(baselink_camera_transformation_file, bc_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmGE2m2mQzIF"},"source":["print(\"Baselink-camera transform: \\n\\n\" + str(bc_transform))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MAAzeDWIP_jd"},"source":["# 6. Test robot-camera calibration\n","\n","> In wat volgt kunnen we de robot-camera kalibratie testen. De inverse van de berekende ${}^{B}T_{C}$ kan namelijk punten gedefiniëerd in robot frame omzetten in camera frame. Samen met de intrinsieke matrix kunnen we dus punten omzetten van robot frame in pixel frame en dus virtueel geplaatste objecten in robot frame visualiseren in de afbeelding. We definiëren hier een kubus in coördinaten gedefiniëerd ten opzichte van het robot frame. \n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"nNXQppMZQYk1"},"source":["# Define axis and box coordinates in world coordinate system\n","box = np.float32([[-0.1, -0.6, 0], [-0.1, -0.7, 0], [-0.2, -0.7, 0], \n","                  [-0.2, -0.6, 0], [-0.1, -0.6, -0.1], [-0.1, -0.7, -0.1], [-0.2, -0.7, -0.1], \n","                  [-0.2, -0.6, -0.1]]).reshape(-1, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Y5vBBJhhiuQ"},"source":["\n","\n","> We willen nu punten gedefiniëerd in baselinkframe omzetten in camera frame. Dus hebben we de geïnverteerde nodig van ${}^{B}T_{C}$, namelijk ${}^{C}T_{B}$. \n","\n"]},{"cell_type":"code","metadata":{"id":"P_TBPvpNQEGl"},"source":["# Invert transform\n","cb_transform = invert_transform(bc_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"80N1AahKh45X"},"source":["\n","> Uit de berekende baselink-camera matrix kunnen we afzonderlijk het rotatie gedeelte en het translatiegedeelte uithalen. Deze dienen we afzonderlijk aan het kalibratie algoritme te geven. \n","\n","$${}^{C}T_{B} = \\begin{bmatrix} r_{11} & r_{12} & r_{13} & t_{x} \\\\ r_{21} & r_{22} & r_{23} & t_{y} \\\\ r_{31} & r_{32} & r_{33} & t_{z}\\\\ 0 & 0 & 0 & 1 \\end{bmatrix} ; {}^{C}R_{B} = \\begin{bmatrix} r_{11} & r_{12} & r_{13}\\\\ r_{21} & r_{22} & r_{23}\\\\ r_{31} & r_{32} & r_{33}\\end{bmatrix} ; {}^{C}t_{B} = \\begin{bmatrix} t_{x} \\\\ t_{y} \\\\ t_{z}\\end{bmatrix}$$"]},{"cell_type":"code","metadata":{"id":"w_hOkVYyhy1j"},"source":["# Retrieve rotation matrix and translation vector from cb_transform\n","cb_rot = cb_transform[:3, :3]\n","cb_trans = cb_transform[0:3, 3]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZbqOEQo9iFwd"},"source":["> Hier projecteren we de gedefiniëerde metrische coördinaten van de kubus (box) beschreven in het baselink frame in pixelcoördinaten en tekenen we deze op de afbeelding. Merk terug op dat aan de functie 'cv2.projectPoints' nu de translatie en rotatie matrices van het cameraframe naar het baselink frame worden meegegeven, dit was niet zo in het vorige script, daar waren dit de matrices van camera frame naar target frame. "]},{"cell_type":"code","metadata":{"id":"MtGzMOZkQEI6"},"source":["# Project 3D box points to pixel coordinates\n","imgpts_box, _ = cv2.projectPoints(box, cb_rot, cb_trans, mtx, dist)\n","\n","# Draw box on image\n","image = draw_box1(image, imgpts_box)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mzpu_8YCiNG8"},"source":["\n","\n","> Plot hieronder de afbeeldingen met de geprojecteerde pixels.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"y_9XNcfMQELR"},"source":["# Show result\n","cv2_imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EmbbJ9hhiil8"},"source":["\n","> Het resultaat laat inderdaad zien dat de gedefiniëerde kubus in baselink frame coördinaten mooi de juiste pixels triggert om het effect te creëren dat deze effectief in de ruimte aanwezig is. Je brein zal hoogst waarschijnlijk even de tijd nodig hebben om te zien dat de kubus wel degenlijk correct geplaatst is voor de robot. Je kan zelf wat spelen door de coördinaten van de kubus te veranderen.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"URorVLfZPxG0"},"source":["> Je kan ook zelf kijken welke pixels worden getriggerd door punten in metrische coördinaten, gedefiniëerd in het baselink frame te projecteren in pixel frame."]},{"cell_type":"code","metadata":{"id":"EtMZE4zCP1Ax"},"source":["# Define point\n","point = np.float32([0, 0, 0])\n","\n","# Project 3D point to pixel coordinates\n","imgpts_point, _ = cv2.projectPoints(point, cb_rot, cb_trans, mtx, dist)\n","print(imgpts_point)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0dt0Um5R4oxz"},"source":["*  VRAAG 1: Wat is de x-, y-, en z- positie van de oorsprong van het targetframe {T} in het baselink frame {B} op het moment van het nemen van de eerste foto? \n","*  VRAAG 2: Wat is de x-, y-, en z- positie van de oorsprong van het targetframe {T} in het camera frame {C} op het moment van het nemen van de eerste foto?\n","*  VRAAG 3: Welk pixelcoördinaat wordt er getriggerd als een punt op coördinaat (0, -0.6, 0.0) meter in het baselink frame wordt geplaatst? "]}]}