{"cells":[{"cell_type":"markdown","metadata":{"id":"xAVJIKosYW6g"},"source":["# Real time kalibratie test\n","\n","Het proces van extrinsieke kalibratie dat we vorige opdracht hebben uitgetest kan ook realtime gedaan worden door gebruik te maken van je webcam. Je dient hiervoor het dambordpatroon af te printen en op een hard vlak (karton) te kleven. Als je het patroon voor de camera houdt, dan zal de extrinsieke matrix realtime berekend worden en kan je virtueel gedefiniëerde objecten in het target frame live zien verschijnen op je dambord. Dit is dus hoe Augmented Reality werkt. "]},{"cell_type":"markdown","metadata":{"id":"lK_RVhZIfbeJ"},"source":["# 1. Importeer biliotheken\n","\n","\n","> Deze bibliotheken zijn nodig voor het volbrengen van dit script. In de CameraCalibration bibliotheek (die je vindt in de Classes folder op je Google Drive) vind je de code achter de commando's die je hier zal gebruiken. Deze cel zal een error geven als je niet met je Google Drive bent verbonden. Zorg er dus voor dat je links in de bestanden een folder 'drive' ziet staan naast de default 'sample_data'-folder. Indien niet, verbind met de drive door links op het mapje te klikken en vervolgens op het Google Drive symbool te klikken. Druk vervolgens nog eens op 'Runtime', 'Runtime opnieuw starten', om te refreshen. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiPo44WBjeqd","vscode":{"languageId":"python"}},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/My Drive/object_pose_estimation_online')\n","from Classes.CameraCalibration import *\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"markdown","metadata":{"id":"xZPjLjvNfeo-"},"source":["# 2. Script om toegang te krijgen tot je webcam\n","\n","> Dit is een script om je webcam te kunnen uitlezen. Hier hoef je niets mee te doen.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"uGIzTP9FnusI","vscode":{"languageId":"python"}},"outputs":[],"source":["#@title javascript_code\n","import base64\n","import html\n","import io\n","import time\n","\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","import numpy as np\n","from PIL import Image\n","import cv2\n","\n","def start_input():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 512; //video.videoWidth;\n","      captureCanvas.height = 512; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function takePhoto(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)"]},{"cell_type":"markdown","metadata":{"id":"nAuQHI0YgCsC"},"source":["# 4. Laden van de berekende intrinsieke camera matrix\n","\n","> In vorige opgave heb je de intrinsieke matrix opgeslagen, deze werd automatisch opgeslagen onder /content/drive/My Drive/object_pose_estimation_online/data/matrix_files/intrinsic_camera_properties.npz. Deze kunnen we nu laden. De functie \"load_intrinsic_camera_matrix\" geeft je niet enkel de intrinsieke matrix, maar ook de distrotiecoëfficiënten nodig voor de kalibratie. Merk op dat een intrinsieke matrix eigen is aan de camera. De vorig berekende matrix geldt dus enkel voor de camera in het labo. Hoe dan ook zal je een goed effect krijgen met deze matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOqMkL37hval","vscode":{"languageId":"python"}},"outputs":[],"source":["# Load intrinsic camera matrix and distortion coefficients\n","intrinsic_camera_matrix_file = \"/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/intrinsic_camera_properties.npz\"\n","mtx, dist = load_intrinsic_camera_matrix(intrinsic_camera_matrix_file)"]},{"cell_type":"markdown","metadata":{"id":"Alt8L4NVfrTJ"},"source":["# 4. Toon realtime resultaten\n","\n","\n","> We definiëren twee zaken:\n","\n","\n","*   De coordinaten van het target assenstelsel. We definiëren de oorsprong op (X, Y, Z) = (0, 0, 0) in het camera frame, de x-as op (X, Y, Z) = (0.06, 0, 0) , de y-as op (X, Y, Z) = (0, 0.06, 0), en de z-as op (X, Y, Z) = (0, 0, 0.06). \n","*   De coördinaten van een virtuele kubus van 0.04x0.04x0.04 meter in het target frame.\n","\n","\n","> Voor deze beide zaken maken we gebruik van de intrinsieke en extrinsieke matrix om te kijken met welke pixels deze overeenkomen. Als we deze pixels berekenen en projecteren op het beeld, dan krijgen we het effect alsof deze zaken zich werkelijk in de ruimte (gedefiniëerd in target frame) bevinden."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wU7DiR7OhzSJ","vscode":{"languageId":"python"}},"outputs":[],"source":["# Axis coordinates in world coordinates system\n","axis = np.float32([[0.06, 0, 0], [0, 0.06, 0], [0, 0, 0.06], [0, 0, 0]])\n","box = np.float32([[0.08, 0.06, 0], [0.12, 0.06, 0], [0.12, 0.10, 0], [0.08, 0.10, 0], [0.08, 0.06, -0.04],\n","                          [0.12, 0.06, -0.04], [0.12, 0.10, -0.04], [0.08, 0.10, -0.04]]).reshape(-1, 3)"]},{"cell_type":"markdown","metadata":{"id":"ukekf4yNaHQD"},"source":["\n","\n","> Als je dit script runt zal je onderaan je webcam output zien verschijnen. Let op dat er niets gebeurt als er geen dambordpatroon wordt gedetecteerd. De processing kan wat traag verlopen zodat ze in het begin wat dingen ziet die niet correct zijn. Hou hiervoor je dambordpatroon wat plat (niet frontaal tov de webcam) en hou dit stabiel. Je kan het filmen stoppen door op 'Runtime => Uitvoering Onderbreken' te klikken of door je webtabblad te sluiten. \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNW-S4NicjtO","vscode":{"languageId":"python"}},"outputs":[],"source":["# Start webcam\n","start_input()\n","label_html = 'Capturing...'\n","img_data = ''\n","\n","# Loop\n","while True:\n","\n","    # Get image from webcam\n","    data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label_html, img_data))\n","    jpeg_bytes = base64.b64decode(data['img'].split(',')[1])\n","    image_PIL = Image.open(io.BytesIO(jpeg_bytes))\n","    image_array = np.array(image_PIL)\n","\n","    # Turn image to grayscale\n","    gray = image_to_grayscale(image_array)  \n","\n","    # Find the corners in the chessbord calibration tool\n","    corners = find_corners(gray)\n","\n","    # Creating empty drawing image\n","    drawing_array = np.zeros([512,512,4], dtype=np.uint8)  \n","\n","    # Get extrinsic camera calibration matrix (target - camera transform)\n","    if not corners is None:\n","\n","      # Prepare object points in 3D space in meters\n","      objp = get_object_points()\n","\n","      # Extrinsic camera calibration\n","      ct_transform = extrinsic_calibration(objp, corners, mtx, dist)\n","\n","      # Retrieve rotation matrix and translation vector from ct_transform\n","      ct_rot = ct_transform[:3, :3]\n","      ct_trans = ct_transform[0:3, 3] \n","    \n","      # Project 3D axis points to pixel coordinates\n","      imgpts, jac = cv2.projectPoints(axis, ct_rot, ct_trans, mtx, dist)\n","\n","      # Draw axis on image\n","      drawing_array = draw_axis(drawing_array, imgpts.astype(int))\n","\n","      # Project 3D box points to pixel coordinates\n","      imgpts, jac = cv2.projectPoints(box, ct_rot, ct_trans, mtx, dist)\n","\n","      # Draw box on image\n","      drawing_array = draw_box1(drawing_array, imgpts.astype(int))\n","      drawing_array[:,:,3] = (drawing_array.max(axis = 2) > 0 ).astype(int) * 255\n","\n","    # Send new image to javascript\n","    drawing_PIL = Image.fromarray(drawing_array, 'RGBA')\n","    iobuf = io.BytesIO()\n","    drawing_PIL.save(iobuf, format='png')\n","    drawing_bytes = 'data:image/png;base64,{}'.format((str(base64.b64encode(iobuf.getvalue()), 'utf-8')))\n","    img_data = drawing_bytes\n","    "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO4GLaAHJxLh5RV9R/QZ6Nt","collapsed_sections":[],"mount_file_id":"1-skXYQ3y3wHiy3H0YQdIBVIkkuWtbgpo","name":"4_realtime_calibration_test.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
